{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7196a3e8-82d1-44af-8ebc-98d4677b7d1b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import ast\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dea109c6-9b37-41ed-b319-8e7ca5a6134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(r\"D:\\PYTHON\\Projects\\Movie-Recommendation-System\\movies.csv\")\n",
    "credits = pd.read_csv(r\"D:\\PYTHON\\Projects\\Movie-Recommendation-System\\credits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0f53dc4-3541-4bdb-8d37-42ce6190cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.merge(credits, on=\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aee6ea7b-4628-4991-a5d8-fe175af466e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[[\"movie_id\", \"title\", \"overview\", \"genres\", \"keywords\", \"cast\", \"crew\"]]\n",
    "movies.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92322106-bdfc-4915-88fa-6d54cf79e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(text):\n",
    "    l = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        l.append(i[\"name\"])\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c975bfa-e2a9-4c62-a890-f810a1725f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cast(text):\n",
    "    l = []\n",
    "    counter = 0\n",
    "    for i in ast.literal_eval(text):\n",
    "        if counter < 3:\n",
    "            l.append(i['name'])\n",
    "        counter += 1\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ed2e67a-7168-4d38-8c82-4b19bbd613ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_director(text):\n",
    "    l = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        if i['job'] == 'Director':\n",
    "            l.append(i['name'])\n",
    "            break\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a5563bb-c6d4-4681-b350-1e6d587ba67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "movies['cast'] = movies['cast'].apply(convert_cast)\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d98b424a-4c9a-4d13-9eb2-6502b279b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['overview'] = movies['overview'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a25e58b-8354-43d4-98f5-5f2dd3b55cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space(word):\n",
    "    l = []\n",
    "    for i in word:\n",
    "        l.append(i.replace(\" \", ''))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e5637ca-af84-4629-850e-039428549bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['cast'] = movies['cast'].apply(remove_space)\n",
    "movies['crew'] = movies['crew'].apply(remove_space)\n",
    "movies['genres'] = movies['genres'].apply(remove_space)\n",
    "movies['keywords'] = movies['keywords'].apply(remove_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "722d5936-f390-48b8-bd3b-91fced1d2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7688108-aef3-4c03-8854-bb79ac07caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = movies[['movie_id', 'title', 'tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d849afe-5ee5-46c9-a34c-71a28d077547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\AppData\\Local\\Temp\\ipykernel_10548\\2959733794.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n",
      "C:\\Users\\priya\\AppData\\Local\\Temp\\ipykernel_10548\\2959733794.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))\n",
    "new_df['tags'] = new_df['tags'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24f97860-0ffc-44a5-acff-32ad30e0a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stems(text):\n",
    "    l = []\n",
    "    for i in text.split():\n",
    "        l.append(ps.stem(i))\n",
    "    return \" \".join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5bc8e305-2549-4690-997b-2f78b3593df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\AppData\\Local\\Temp\\ipykernel_10548\\3973021881.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['tags'] = new_df['tags'].apply(stems)\n"
     ]
    }
   ],
   "source": [
    "new_df['tags'] = new_df['tags'].apply(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dba1f778-db7a-4500-8f2c-91522530d241",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cv \u001b[38;5;241m=\u001b[39m CountVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m, stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m vector \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1381\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1386\u001b[0m             )\n\u001b[0;32m   1387\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1389\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1392\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1295\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1293\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1295\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1296\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1297\u001b[0m         )\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(max_features=5000, stop_words='english')\n",
    "vector = cv.fit_transform(new_df['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e142dfc-9e19-48e2-8f6f-61664dbc18f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(\u001b[43mvector\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vector' is not defined"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "140ef9de-6953-4a39-abf4-1271a2ade884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    index = new_df[new_df['title'] == movie].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[index])), reverse=True, key=lambda x: x[1])\n",
    "    for i in distances[1: 6]:\n",
    "        print(new_df.loc[i[0]].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce21a54d-0a1a-499f-b6fb-454bdffa7198",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarity' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSpider-Man\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m, in \u001b[0;36mrecommend\u001b[1;34m(movie)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend\u001b[39m(movie):\n\u001b[0;32m      2\u001b[0m     index \u001b[38;5;241m=\u001b[39m new_df[new_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m movie]\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[43msimilarity\u001b[49m[index])), reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m distances[\u001b[38;5;241m1\u001b[39m: \u001b[38;5;241m6\u001b[39m]:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(new_df\u001b[38;5;241m.\u001b[39mloc[i[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mtitle)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'similarity' is not defined"
     ]
    }
   ],
   "source": [
    "recommend('Spider-Man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d6ce09-cd07-4252-b343-3a62f5bcea5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
